{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5737d3c1",
   "metadata": {},
   "source": [
    "# Tunning parameters in Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbc24f",
   "metadata": {},
   "source": [
    "Hello, today we are going to tune some hyperparemters in Neural Networks by using Keras.\n",
    "\n",
    "Previously we have created a new neural network in TFLEARN for the MMORPG-AI problem.\n",
    "and we have rewritten in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7e36f",
   "metadata": {},
   "source": [
    "## Tune Batch Size and Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61466bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18e9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49bc75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "#Importing mmorpg library\n",
    "from mmorpg import *\n",
    "#We define the parameters\n",
    "width= 480\n",
    "height= 270\n",
    "ncolors=3\n",
    "#Normalization Parameter\n",
    "Norma        = 29/1000\n",
    "#Paramters                          Operation \n",
    "filters1     =  roundeven(96*Norma)   #1\n",
    "kernel1      =  11       \n",
    "stride1      =  4\n",
    "kernel2      =  3                     #2\n",
    "stride2      =  2\n",
    "filters3     =  roundeven(256*Norma)  #3\n",
    "kernel3      =  5\n",
    "kernel4      =  3                     #4\n",
    "stride4      =  2\n",
    "filters5     =  roundeven(384*Norma)  #5\n",
    "kernel5      =  3\n",
    "filters6     =  roundeven(384*Norma)  #6\n",
    "kernel6      =  3\n",
    "filters7     =  roundeven(256*Norma)  #7\n",
    "kernel7      =  3\n",
    "kernel8      =  3                      #8\n",
    "stride8      =  2 \n",
    "activation9  =  roundeven(4096*Norma)  #9\n",
    "activation10 =  roundeven(4096*Norma)  #10\n",
    "outputs11    =  int(1000*Norma)   #11\n",
    "\n",
    "dropout13=0.5\n",
    "dropout15=0.5\n",
    "learning_rate17=0.001\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "179331e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    #model = Sequential()\n",
    "    #model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    #model.add(Dense(1, activation='sigmoid'))\n",
    "    #Instantiation\n",
    "    MmoNet = Sequential()\n",
    "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
    "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
    "    #3rd Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #4th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #5th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
    "    #Passing it to a Fully Connected layer\n",
    "    MmoNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    MmoNet.add(Dropout(dropout13))\n",
    "    #2nd Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation10))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #3rd Fully Connected Layer\n",
    "    MmoNet.add(Dense(1000))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #Output Layer\n",
    "    MmoNet.add(Dense(outputs11))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    MmoNet.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return MmoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8988f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b23b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Gamepad library\n",
    "from mmorpg import *\n",
    "#We load the images of the gameplay\n",
    "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
    "#We load the inputs of the of the gameplay\n",
    "y_training_data=pd.read_pickle('data/dfy-0.pkl')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,width,height,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,width,height,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a75e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMAGANAV\\Anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa3619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100, 200]\n",
    "epochs = [10, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9fa4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10,  40 ]\n",
    "epochs = [10,  100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51afcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_image, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90dad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4e5c6",
   "metadata": {},
   "source": [
    "# Tune the Training Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    MmoNet = Sequential()\n",
    "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
    "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
    "    #3rd Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #4th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #5th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
    "    #Passing it to a Fully Connected layer\n",
    "    MmoNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    MmoNet.add(Dropout(dropout13))\n",
    "    #2nd Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation10))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #3rd Fully Connected Layer\n",
    "    MmoNet.add(Dense(1000))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #Output Layer\n",
    "    MmoNet.add(Dense(outputs11))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    MmoNet.compile(loss='binary_crossentropy',  optimizer=optimizer, metrics=['accuracy'])\n",
    "    return MmoNet\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "#Importing Gamepad library\n",
    "from mmorpg import *\n",
    "#We load the images of the gameplay\n",
    "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
    "#We load the inputs of the of the gameplay\n",
    "y_training_data=pd.read_pickle('data/dfy-0.pkl')  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,width,height,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,width,height,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_image, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbf775",
   "metadata": {},
   "source": [
    "# Tune Learning Rate and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c38bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the learning rate and momentum\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    MmoNet = Sequential()\n",
    "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
    "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
    "    #3rd Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #4th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #5th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
    "    #Passing it to a Fully Connected layer\n",
    "    MmoNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    MmoNet.add(Dropout(dropout13))\n",
    "    #2nd Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation10))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #3rd Fully Connected Layer\n",
    "    MmoNet.add(Dense(1000))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #Output Layer\n",
    "    MmoNet.add(Dense(outputs11))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    MmoNet.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return MmoNet\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "#Importing Gamepad library\n",
    "from mmorpg import *\n",
    "#We load the images of the gameplay\n",
    "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
    "#We load the inputs of the of the gameplay\n",
    "y_training_data=pd.read_pickle('data/dfy-0.pkl')  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,width,height,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,width,height,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3e0ed",
   "metadata": {},
   "source": [
    "References :https://pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/ \n",
    "            https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddc0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras)",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
