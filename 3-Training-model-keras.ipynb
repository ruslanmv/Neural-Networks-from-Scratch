{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions about mmorpg-ai project\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import io\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "import os\n",
    "\n",
    "def df_to_numpy_image(df_image_clean,index):\n",
    "    #select the row with index label 'index'\n",
    "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
    "    lists =image_clean.tolist()\n",
    "    # Nested List Comprehension to flatten a given 2-D matrix\n",
    "    # 2-D List\n",
    "    matrix = lists\n",
    "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
    "    # converting list to array\n",
    "    arr = np.array(flatten_matrix)\n",
    "    return arr\n",
    "def df_to_numpy_input(df_input,index): \n",
    "    # flattening a 2d numpy array\n",
    "    # into 1d array\n",
    "    # and remove dtype at the end of numpy array\n",
    "    lista=df_input.loc[[index]].values.tolist()\n",
    "    arr=np.array(lista).ravel()\n",
    "    return arr\n",
    "#round a float up to next even number\n",
    "import math\n",
    "def roundeven(f):\n",
    "    return math.ceil(f / 2.) * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the parameters\n",
    "width= 480\n",
    "height= 270\n",
    "ncolors=3\n",
    "#Normalization Parameter\n",
    "Norma        = 29/1000\n",
    "#Paramters                          Operation \n",
    "filters1     =  roundeven(96*Norma)   #1\n",
    "kernel1      =  11       \n",
    "stride1      =  4\n",
    "kernel2      =  3                     #2\n",
    "stride2      =  2\n",
    "filters3     =  roundeven(256*Norma)  #3\n",
    "kernel3      =  5\n",
    "kernel4      =  3                     #4\n",
    "stride4      =  2\n",
    "filters5     =  roundeven(384*Norma)  #5\n",
    "kernel5      =  3\n",
    "filters6     =  roundeven(384*Norma)  #6\n",
    "kernel6      =  3\n",
    "filters7     =  roundeven(256*Norma)  #7\n",
    "kernel7      =  3\n",
    "kernel8      =  3                      #8\n",
    "stride8      =  2 \n",
    "activation9  =  roundeven(4096*Norma)  #9\n",
    "activation10 =  roundeven(4096*Norma)  #10\n",
    "outputs11    =  int(1000*Norma)   #11\n",
    "dropout13=0.5\n",
    "dropout15=0.5\n",
    "learning_rate17=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We load the datasets to work\n",
    "import os\n",
    "user = \"ruslanmv\"\n",
    "repo = \"Neural-Networks-from-Scratch\"\n",
    "# remove local directory if it already exists\n",
    "if os.path.isdir(repo):\n",
    "    !rm -rf {repo}\n",
    "!git clone https://github.com/{user}/{repo}.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model MmoNet\n",
    "def create_model(optimizer='adam',learn_rate=0.1, momentum=0):\n",
    "    # create model\n",
    "    MmoNet = Sequential()\n",
    "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
    "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
    "    #3rd Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #4th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #5th Convolutional Layer\n",
    "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
    "    #Passing it to a Fully Connected layer\n",
    "    MmoNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    MmoNet.add(Dropout(dropout13))\n",
    "    #2nd Fully Connected Layer\n",
    "    MmoNet.add(Dense(activation10))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #3rd Fully Connected Layer\n",
    "    MmoNet.add(Dense(1000))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    MmoNet.add(Dropout(dropout15))\n",
    "    #Output Layer\n",
    "    MmoNet.add(Dense(outputs11))\n",
    "    MmoNet.add(BatchNormalization())\n",
    "    MmoNet.add(Activation('softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    \n",
    "\n",
    "    MmoNet.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return MmoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#We load the images of the gameplay\n",
    "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
    "#We load the inputs of the of the gameplay\n",
    "y_training_data=pd.read_pickle('data/dfy-0.pkl')  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,width,height,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,width,height,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
