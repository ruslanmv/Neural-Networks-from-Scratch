{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!--NAVIGATION-->\n",
        "<a href=\"https://colab.research.google.com/github/ruslanmv/Neural-Networks-from-Scratch/blob/master/3_How_to_tune_parameters_in_neural_networks_colab.ipynb\"> <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n",
        "<a href=\"https://github.com/ruslanmv/Neural-Networks-from-Scratch/blob/master/3_How_to_tune_parameters_in_neural_networks_colab.ipynb\"> <img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
      ],
      "metadata": {
        "id": "cCBYl4blJfTs"
      },
      "id": "cCBYl4blJfTs"
    },
    {
      "cell_type": "markdown",
      "id": "5737d3c1",
      "metadata": {
        "id": "5737d3c1"
      },
      "source": [
        "# Tunning parameters in Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bcbc24f",
      "metadata": {
        "id": "3bcbc24f"
      },
      "source": [
        "Hello, today we are going to tune some hyperparemters in Neural Networks by using Keras.\n",
        "\n",
        "Previously we have created a new neural network in TFLEARN for the MMORPG-AI problem.\n",
        "and we have rewritten in Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44e7e36f",
      "metadata": {
        "id": "44e7e36f"
      },
      "source": [
        "## Tune Batch Size and Number of Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a61466bc",
      "metadata": {
        "id": "a61466bc"
      },
      "outputs": [],
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a18e9d1c",
      "metadata": {
        "id": "a18e9d1c"
      },
      "outputs": [],
      "source": [
        "#Importing library\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b49bc75f",
      "metadata": {
        "id": "b49bc75f"
      },
      "outputs": [],
      "source": [
        "#Helper functions about mmorpg-ai project\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import io\n",
        "from IPython.display import clear_output, Image, display\n",
        "import PIL.Image\n",
        "from matplotlib import pyplot as plt\n",
        "import logging, sys\n",
        "logging.disable(sys.maxsize)\n",
        "import os\n",
        "\n",
        "def df_to_numpy_image(df_image_clean,index):\n",
        "    #select the row with index label 'index'\n",
        "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
        "    lists =image_clean.tolist()\n",
        "    # Nested List Comprehension to flatten a given 2-D matrix\n",
        "    # 2-D List\n",
        "    matrix = lists\n",
        "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
        "    # converting list to array\n",
        "    arr = np.array(flatten_matrix)\n",
        "    return arr\n",
        "def df_to_numpy_input(df_input,index): \n",
        "    # flattening a 2d numpy array\n",
        "    # into 1d array\n",
        "    # and remove dtype at the end of numpy array\n",
        "    lista=df_input.loc[[index]].values.tolist()\n",
        "    arr=np.array(lista).ravel()\n",
        "    return arr\n",
        "#round a float up to next even number\n",
        "import math\n",
        "def roundeven(f):\n",
        "    return math.ceil(f / 2.) * 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We define the parameters\n",
        "width= 480\n",
        "height= 270\n",
        "ncolors=3\n",
        "#Normalization Parameter\n",
        "Norma        = 29/1000\n",
        "#Paramters                          Operation \n",
        "filters1     =  roundeven(96*Norma)   #1\n",
        "kernel1      =  11       \n",
        "stride1      =  4\n",
        "kernel2      =  3                     #2\n",
        "stride2      =  2\n",
        "filters3     =  roundeven(256*Norma)  #3\n",
        "kernel3      =  5\n",
        "kernel4      =  3                     #4\n",
        "stride4      =  2\n",
        "filters5     =  roundeven(384*Norma)  #5\n",
        "kernel5      =  3\n",
        "filters6     =  roundeven(384*Norma)  #6\n",
        "kernel6      =  3\n",
        "filters7     =  roundeven(256*Norma)  #7\n",
        "kernel7      =  3\n",
        "kernel8      =  3                      #8\n",
        "stride8      =  2 \n",
        "activation9  =  roundeven(4096*Norma)  #9\n",
        "activation10 =  roundeven(4096*Norma)  #10\n",
        "outputs11    =  int(1000*Norma)   #11\n",
        "\n",
        "dropout13=0.5\n",
        "dropout15=0.5\n",
        "learning_rate17=0.001\n",
        "np.random.seed(1000)"
      ],
      "metadata": {
        "id": "ptjsox84C8xq"
      },
      "id": "ptjsox84C8xq",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "179331e5",
      "metadata": {
        "id": "179331e5"
      },
      "outputs": [],
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "    # create model\n",
        "    #model = Sequential()\n",
        "    #model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "    #model.add(Dense(1, activation='sigmoid'))\n",
        "    #Instantiation\n",
        "    MmoNet = Sequential()\n",
        "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
        "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
        "    #3rd Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #4th Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #5th Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
        "    #Passing it to a Fully Connected layer\n",
        "    MmoNet.add(Flatten())\n",
        "    # 1st Fully Connected Layer\n",
        "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    MmoNet.add(Dropout(dropout13))\n",
        "    #2nd Fully Connected Layer\n",
        "    MmoNet.add(Dense(activation10))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #Add Dropout\n",
        "    MmoNet.add(Dropout(dropout15))\n",
        "    #3rd Fully Connected Layer\n",
        "    MmoNet.add(Dense(1000))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #Add Dropout\n",
        "    MmoNet.add(Dropout(dropout15))\n",
        "    #Output Layer\n",
        "    MmoNet.add(Dense(outputs11))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('softmax'))\n",
        "    # Compile model\n",
        "    MmoNet.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return MmoNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8988f17b",
      "metadata": {
        "id": "8988f17b"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the datasets to work"
      ],
      "metadata": {
        "id": "JJJaRobbF7F6"
      },
      "id": "JJJaRobbF7F6"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HXF65YgvPrH",
        "nbpages": {
          "level": 2,
          "link": "[A.2.2 Method 2. Cloning a git repository](https://jckantor.github.io/cbe61622/A.02-Downloading_Python_source_files_from_github.html#A.2.2-Method-2.-Cloning-a-git-repository)",
          "section": "A.2.2 Method 2. Cloning a git repository"
        },
        "outputId": "77670e15-a4ee-41ee-a5ce-f2019a910669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Neural-Networks-from-Scratch'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 144 (delta 37), reused 27 (delta 13), pack-reused 84\u001b[K\n",
            "Receiving objects: 100% (144/144), 317.29 MiB | 33.24 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "Checking out files: 100% (45/45), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "user = \"ruslanmv\"\n",
        "repo = \"Neural-Networks-from-Scratch\"\n",
        "# remove local directory if it already exists\n",
        "if os.path.isdir(repo):\n",
        "    !rm -rf {repo}\n",
        "!git clone https://github.com/{user}/{repo}.git"
      ],
      "id": "8HXF65YgvPrH"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('Neural-Networks-from-Scratch')"
      ],
      "metadata": {
        "id": "zlNVJKZgFYSZ"
      },
      "id": "zlNVJKZgFYSZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Neural-Networks-from-Scratch/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqvzA1eFFlmC",
        "outputId": "348398c7-c34b-4bca-ff8c-da91f5f6c651"
      },
      "id": "CqvzA1eFFlmC",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dfx-0.pkl  dfx-1.pkl  dfx-2.pkl  dfy-0.pkl  dfy-1.pkl  dfy-2.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Gamepad library\n",
        "#We load the images of the gameplay\n",
        "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
        "#We load the inputs of the of the gameplay\n",
        "y_training_data=pd.read_pickle('data/dfy-0.pkl')"
      ],
      "metadata": {
        "id": "a0Gs7NbyEwjb"
      },
      "id": "a0Gs7NbyEwjb",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f2b23b64",
      "metadata": {
        "id": "f2b23b64"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
        "# Train Image part ( 4 Dimensional)\n",
        "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
        "X=X_image.reshape(-1,width,height,3)\n",
        "#Train Input part ( 1 Dimensional )\n",
        "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
        "# Test Image part ( 4 Dimensional)\n",
        "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
        "test_x=test_image.reshape(-1,width,height,3)\n",
        "## Test Input part( 1 Dimensional )\n",
        "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9a75e7e8",
      "metadata": {
        "id": "9a75e7e8",
        "outputId": "8072c828-7d25-49ff-a573-ccde19ddb2d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7fa3619e",
      "metadata": {
        "id": "7fa3619e"
      },
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 40, 80, 100]\n",
        "epochs = [10, 50, 100, 200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cd9fa4ee",
      "metadata": {
        "id": "cd9fa4ee"
      },
      "outputs": [],
      "source": [
        "# define test the grid search parameters\n",
        "#batch_size = [10,  40 ]\n",
        "#epochs = [10,  100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "51afcd84",
      "metadata": {
        "id": "51afcd84"
      },
      "outputs": [],
      "source": [
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "362f7054",
      "metadata": {
        "id": "362f7054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d669fdb7-4040-44a6-ad05-a72fdabcd240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        }
      ],
      "source": [
        "grid_result = grid.fit(X_image, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c90dad25",
      "metadata": {
        "id": "c90dad25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ef3783-d6f7-40ee-b246-038544f7f3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.784336 using {'batch_size': 80, 'epochs': 100}\n",
            "0.045304 (0.044657) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.484622 (0.133055) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.477461 (0.349394) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.099502 (0.071406) with: {'batch_size': 10, 'epochs': 200}\n",
            "0.442786 (0.343031) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.681441 (0.418576) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.462687 (0.384793) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.035203 (0.031159) with: {'batch_size': 20, 'epochs': 200}\n",
            "0.039801 (0.056287) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.758480 (0.216292) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.731193 (0.358937) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.382708 (0.386830) with: {'batch_size': 40, 'epochs': 200}\n",
            "0.000000 (0.000000) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.512739 (0.384310) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.784336 (0.135371) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.646842 (0.447046) with: {'batch_size': 80, 'epochs': 200}\n",
            "0.000000 (0.000000) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.243781 (0.344759) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.115257 (0.060808) with: {'batch_size': 100, 'epochs': 100}\n",
            "0.433213 (0.386561) with: {'batch_size': 100, 'epochs': 200}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8c4e5c6",
      "metadata": {
        "id": "f8c4e5c6"
      },
      "source": [
        "# Tune the Training Optimization Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "332b4b7a",
      "metadata": {
        "id": "332b4b7a"
      },
      "outputs": [],
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "    # create model\n",
        "    MmoNet = Sequential()\n",
        "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
        "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
        "    #3rd Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #4th Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #5th Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
        "    #Passing it to a Fully Connected layer\n",
        "    MmoNet.add(Flatten())\n",
        "    # 1st Fully Connected Layer\n",
        "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    MmoNet.add(Dropout(dropout13))\n",
        "    #2nd Fully Connected Layer\n",
        "    MmoNet.add(Dense(activation10))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #Add Dropout\n",
        "    MmoNet.add(Dropout(dropout15))\n",
        "    #3rd Fully Connected Layer\n",
        "    MmoNet.add(Dense(1000))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #Add Dropout\n",
        "    MmoNet.add(Dropout(dropout15))\n",
        "    #Output Layer\n",
        "    MmoNet.add(Dense(outputs11))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('softmax'))\n",
        "    # Compile model\n",
        "    MmoNet.compile(loss='binary_crossentropy',  optimizer=optimizer, metrics=['accuracy'])\n",
        "    return MmoNet\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "#We load the images of the gameplay\n",
        "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
        "#We load the inputs of the of the gameplay\n",
        "y_training_data=pd.read_pickle('data/dfy-0.pkl')  \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
        "# Train Image part ( 4 Dimensional)\n",
        "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
        "X=X_image.reshape(-1,width,height,3)\n",
        "#Train Input part ( 1 Dimensional )\n",
        "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
        "# Test Image part ( 4 Dimensional)\n",
        "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
        "test_x=test_image.reshape(-1,width,height,3)\n",
        "## Test Input part( 1 Dimensional )\n",
        "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "81ca4fb2",
      "metadata": {
        "id": "81ca4fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a9204d-19d4-4780-c0c3-d7b1e3775cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=80, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9ad8899c",
      "metadata": {
        "id": "9ad8899c"
      },
      "outputs": [],
      "source": [
        "grid_result = grid.fit(X_image, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "00a1cd57",
      "metadata": {
        "id": "00a1cd57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8272e0c-61c9-4b4d-9484-947ac58c1e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.694784 using {'optimizer': 'Nadam'}\n",
            "0.074702 (0.095133) with: {'optimizer': 'SGD'}\n",
            "0.373134 (0.445933) with: {'optimizer': 'RMSprop'}\n",
            "0.000000 (0.000000) with: {'optimizer': 'Adagrad'}\n",
            "0.050505 (0.071425) with: {'optimizer': 'Adadelta'}\n",
            "0.060606 (0.085710) with: {'optimizer': 'Adam'}\n",
            "0.000000 (0.000000) with: {'optimizer': 'Adamax'}\n",
            "0.694784 (0.233556) with: {'optimizer': 'Nadam'}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6adbf775",
      "metadata": {
        "id": "6adbf775"
      },
      "source": [
        "# Tune Learning Rate and Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2c38bc7a",
      "metadata": {
        "id": "2c38bc7a"
      },
      "outputs": [],
      "source": [
        "# Use scikit-learn to grid search the learning rate and momentum\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "    # create model\n",
        "    MmoNet = Sequential()\n",
        "    MmoNet.add(Conv2D(filters=filters1, input_shape=(height, width, ncolors), kernel_size=(11,11), strides=(stride1,stride1), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel2,kernel2), strides=(stride2,stride2), padding='same'))\n",
        "    MmoNet.add(Conv2D(filters=filters3, kernel_size=(kernel3, kernel3), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel4,kernel4), strides=(stride4,stride4), padding='same'))\n",
        "    #3rd Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters5, kernel_size=(kernel5,kernel5), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #4th Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters6, kernel_size=( kernel6, kernel6), padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #5th Convolutional Layer\n",
        "    MmoNet.add(Conv2D(filters=filters7, kernel_size=(kernel7,kernel7),  padding='same'))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    MmoNet.add(MaxPooling2D(pool_size=(kernel8,kernel8), strides=(stride8,stride8), padding='same'))\n",
        "    #Passing it to a Fully Connected layer\n",
        "    MmoNet.add(Flatten())\n",
        "    # 1st Fully Connected Layer\n",
        "    MmoNet.add(Dense(activation9, input_shape=(270, 480, 3,)))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    MmoNet.add(Dropout(dropout13))\n",
        "    #2nd Fully Connected Layer\n",
        "    MmoNet.add(Dense(activation10))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #Add Dropout\n",
        "    MmoNet.add(Dropout(dropout15))\n",
        "    #3rd Fully Connected Layer\n",
        "    MmoNet.add(Dense(1000))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('relu'))\n",
        "    #Add Dropout\n",
        "    MmoNet.add(Dropout(dropout15))\n",
        "    #Output Layer\n",
        "    MmoNet.add(Dense(outputs11))\n",
        "    MmoNet.add(BatchNormalization())\n",
        "    MmoNet.add(Activation('softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "    MmoNet.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return MmoNet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "#We load the images of the gameplay\n",
        "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
        "#We load the inputs of the of the gameplay\n",
        "y_training_data=pd.read_pickle('data/dfy-0.pkl')  \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
        "# Train Image part ( 4 Dimensional)\n",
        "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
        "X=X_image.reshape(-1,width,height,3)\n",
        "#Train Input part ( 1 Dimensional )\n",
        "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
        "# Test Image part ( 4 Dimensional)\n",
        "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
        "test_x=test_image.reshape(-1,width,height,3)\n",
        "## Test Input part( 1 Dimensional )\n",
        "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
        "\n"
      ],
      "metadata": {
        "id": "Iq0STdmWkO08"
      },
      "id": "Iq0STdmWkO08",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=80, verbose=0)\n",
        "# define the grid search parameters\n",
        "\n",
        "#Too much memory for Colab\n",
        "#learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "#momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "\n",
        "\n",
        "learn_rate = [0.001, 0.01, 0.1]\n",
        "momentum = [0.0]\n",
        "\n",
        "\n",
        "\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5piuWxE8kR_5",
        "outputId": "9c59a1e8-ca78-4c2e-ad50-660c07823d07"
      },
      "id": "5piuWxE8kR_5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X_image, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib6epCVCkVOP",
        "outputId": "43721c02-0ef8-435b-fb3f-428c4ce4e833"
      },
      "id": "Ib6epCVCkVOP",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyDYbN73sOYZ",
        "outputId": "3761e9ec-0980-45d7-f5e7-2938cab3cc36"
      },
      "id": "JyDYbN73sOYZ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.432685 using {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "0.000000 (0.000000) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "0.000000 (0.000000) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "0.432685 (0.398801) with: {'learn_rate': 0.1, 'momentum': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31c3e0ed",
      "metadata": {
        "id": "31c3e0ed"
      },
      "source": [
        "References :\n",
        "<a href=\"https://pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers\">1</a> <a href=\"https:/machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\">2</a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ddc0f2",
      "metadata": {
        "id": "46ddc0f2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (keras)",
      "language": "python",
      "name": "keras"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": " 3-How-to-tune-parameters-in-neural-networks-colab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}